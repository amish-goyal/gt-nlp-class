{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Project 3: Parsing #\n",
      "\n",
      "In this project, you will build rule-based and statistical parsers. You will build on 3rd-party code. The project has two separate parts:\n",
      "\n",
      "- rule-based CFG parsing\n",
      "- statistical dependency parsing\n",
      "\n",
      "**(Please keep all your results in this notebook, when you submit it.)**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 1 CFG Parsing for Twitter #\n",
      "\n",
      "In this section, you will build a context-free grammar (CFG) for Twitter, using the dataset *oct27.dev* from Project 2.\n",
      "\n",
      "My code **parseTwitter.py** has a function *evalParser()*, which by default will use your grammar to parse all sentences of \n",
      "length less than 10. It will also parse scrambled versions of those sentences, which are assumed to be ungrammatical \n",
      "(of course this is not always true, so the accuracy will be a lower bound). My code calls the **nltk** library, which you may like \n",
      "to learn more about from its [website](http://nltk.org/) and especially [Chap 08 Analyzing Sentence Structure](http://nltk.org/book/ch08.html) of its online book.\n",
      "\n",
      "The ideal parser will produce exactly one parse for every valid English sentence, and zero parses for the scrambled sentences. The \n",
      "scoring works like this:\n",
      "\n",
      "- **true positive**: your parser produces at least one analysis for the original sentence\n",
      "- **false negative**: your parser fails to produce any analysis for the original sentence\n",
      "- **false positive**: your parser produces at least one analysis for a scrambled sentence\n",
      "- **recall, precision, f-measure**: (defined in class)\n",
      "- **parse-per-sent**: the number of parses per analyzed sentence (not counting sentences which could not be parsed). This is a measure of the ambiguity in your parser, and should be as low as possible.\n",
      "\n",
      "Your parser should be specified as a text file, e.g., **lastname-firstname-task1.cfg** for deliverable 1. (All grammars should be submitted \n",
      "and should follow this naming convention.) Each line in a grammar specifies a set of productions, e.g.,\n",
      "\n",
      "- S -> NP VP | S \"&\" S\n",
      "- NP -> \"D\" \"N\" | \"^\"\n",
      "- VP -> VP NP | \"V\"\n",
      "\n",
      "Quotes are used for terminal symbols. For simplicity, your terminal symbols will be at the part-of-speech level, not the original words. \n",
      "You can assume \"gold\" part-of-speech tags as provided in the dataset.\n",
      "\n",
      "Once you have created a CFG, you can evaluate it using **evalParser()**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.1 Getting started ##"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to compute the precision and f-measure, we also need to count the parses for scrambled sentences. \n",
      "For a given (words, tags) pair, one idea to get a scrambled sentence is to use the current word sequence and shuffle the tags. \n",
      "\n",
      "As you can see from **parseTwitter.py**, function **evalParser()** call the parsing function **ChartParser()** from NLTK for parsing (You don't need to the implementation detail of the chart parser.\n",
      "But if you are interested in it, you can find more information \n",
      "from [here](http://nltk.org/api/nltk.parse.html#module-nltk.parse.chart)) and the **getShuffledTags()** function \n",
      "to produce one false positive example, \n",
      "and compute the measurements, such as f-measure and parse-per-sent, etc. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Deliverable 1(a)** Create a CFG that gets perfect recall and only one parse per sentence\n",
      "\n",
      "**Sanity check** It should have very few non-terminals"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With your CFG, you can run the following code to produce the \n",
      "performance report"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "After specifying the file name, run the following code for testing your CFG\n",
      "'''\n",
      "\n",
      "output = evalParser(\"file:lastname-firstname-task1.cfg\")\n",
      "print output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.2 Grammar design ##\n",
      "\n",
      "Now you will create the bst CFG that you can. The grammar in Deliverable 1 gets (at least) 28.6% f-measure, so you'll have to do better\n",
      "than that. Take a close look at the tag definitions in [the POS paper](http://www.ark.cs.cmu.edu/TweetNLP/gimpel+etal.acl11.pdf), \n",
      "and also think about the English grammars discussed in class and in the text.\n",
      "\n",
      "**Deliverable 2(a)** Create the best CFG that you can. Try to maximize f-measure with producing two many analyses per sentence. \n",
      "Submit the grammar and include your results by running the following evaluation code."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Specify the CFG filename and run the code\n",
      "\"\"\"\n",
      "\n",
      "output = evalParser(\"file:lastname-firstname-task2.cfg\") # Specify the filename here\n",
      "print output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Sanity check ** I designed a grammar that get 73.9% f-measure with 1.2 parses per true-positive sentence."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 2(b) ** *evalParser()* has an optional argument max_len. Set max_len=20 to try to parse sentences of length < 20. Report \n",
      "the f-measure and the average number of parses. (Use the same CFG as in deliverable 2)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Specify the CFG filename and run the code\n",
      "\"\"\"\n",
      "\n",
      "output = evalParser(\"file:lastname-firstname-task2.cfg\", max_len=20) # Specify the filename here\n",
      "print output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Sanity check** My CFG gets 72.8% f-measure and on average 1.4 parses per sentence"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 2(c) ** One especially tricky aspect of Twitter parsing are the \"verbal\"\n",
      "tags \"L\", \"M\", and \"Y\". These tags are used for tokens that include both a noun and a \n",
      "verb, like token \"*she'll*\". How do you handle them in your parser?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Your answer here)*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.3 Terminal refinement ##\n",
      "\n",
      "Try to refine the tag set. The function *evalParser()* takes an additional optional \n",
      "argument, **preprocessor**. This argument is the pointer to a function that takes \n",
      "a set of words and tags and performs some additional processing. I've \n",
      "provided a simple example function, **preprocess_example()**, which searchs for the word \n",
      "\"to\" and gives it a new tag \"2\". You can then use this new \"2\" tag in your grammar,\n",
      "giving it different treatment from other prepositions --- for example, it can produce infinitive verb phrases. \n",
      "Other ideas would be to introduce special handling for present and past participle\n",
      "verbs, case marking for pronouns, etc. Section 4 of Klein and Manning's [\"Accurate\n",
      "Unlexicalized Parsing\"](http://acl.ldc.upenn.edu/P/P03/P03-1054.pdf) might give you some other ideas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "This is a example code, please write your own preprocess() function using the code \n",
      "cell in Deliverable 3\n",
      "'''\n",
      "\n",
      "def preprocess_example(words,tags):\n",
      "    for i, (word, tag) in enumerate(zip(words,tags)):\n",
      "        if tag == 'P' and (word.lower() == 'to' or word == '2'):\n",
      "            tags[i] = '2'\n",
      "    return words,tags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 3** Modify the **preprocess()** function to include at least three new tags, and \n",
      "develop a new grammar that uses these tags. Try to improve your f-measure from the previous \n",
      "deliverable. Explain the idea behiind what you did."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preprocess(words,tags):\n",
      "    '''\n",
      "    Fill your code here\n",
      "    '''\n",
      "    return words,tags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once you finish the **preprocess()** function, run the following code to get the performance results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Specify the new defined CFG filename and run the code\n",
      "\"\"\"\n",
      "\n",
      "output = evalParser(\"file:lastname-firstname-task3.cfg\", preprocessor=preprocess) \n",
      "print output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Do not forget to explain your idea here)*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 4 Bakeoff!** Submit your best grammar as **lastname-firstname.cfg**. I will evaluate them all on the test data and \n",
      "present the results in class."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2 Unlabeled dependency parsing #\n",
      "\n",
      "In this section you will work with a structured perceptron dependency parser, which is very similar in design to the structured \n",
      "perceptron sequence labeler that you built in Project 2. In this case you don't need to implement the inference or the learning, \n",
      "just add the 4 different kinds of features incrementally\n",
      "\n",
      "- Distance features\n",
      "- Lexical features\n",
      "- Bilexical features\n",
      "- Contextual features\n",
      "\n",
      "You will see the definition of these features in the following section.\n",
      "\n",
      "You can load in the parser with the following code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('parsing/')\n",
      "sys.path.append('util/')\n",
      "\n",
      "import dependency_parser as depp\n",
      "import dependency_features as depf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.1 Training ##"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The existing parser has only a single arc feature template: the pair of tags involved in each dependency arc. \n",
      "\n",
      "First, without adding any additional features, you should be able to run the code in this section to load data, "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Given the scaffolding code includes everything for this deliverable, \n",
      "this one may not be a suitable problem any more\n",
      "'''\n",
      "\n",
      "dp = depp.DependencyParser(feature_function=depf.DependencyFeatures())\n",
      "dp.read_data(\"english\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " and train a perceptron classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Run the following code to train a perceptron classifier\n",
      "'''\n",
      "\n",
      "dp.train_perceptron(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Sanity check**: after 10 iterations, I get around 51% accuracy on the development data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, you need to think about how to add other features. First, you should familiarize yourself with the feature function in **dependency_features.py** file. \n",
      "In this file, you can see how the POS feature template is implemented in the function **create_arc_features()**.\n",
      "Each feature template is represented as a list of arguments, including a feature template counter. The POS tag feature is \n",
      "implemented as "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Please do NOT run the following code\n",
      "\n",
      "This is just a example code for adding features, \n",
      "Refer \"dependency_features.py\" for more information\n",
      "'''\n",
      "f = self.getF((k, instance.pos[h], instance.pos[m], add))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where the first element inside the list is the feature counter (which prevents collisions), and the second two elements are the POS tags \n",
      "of the head and modifier nodes. The **Instance** class is defined in **dependency_reader.py**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.2 More features ## \n",
      "\n",
      "Now you are ready to add more features to try to improve performance. \n",
      "First, think about the distance features. The intuition of using this feature is the distance between a head and its modifier \n",
      "should not be too far away.\n",
      "\n",
      "- ** Distance features **:  Add features to quantify the distance between the head and modifier in each dependency arc. \n",
      "\n",
      "** Deliverable 5 ** How does this impact dev set accuracy (after 10 iterations) and the total number of features?\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "After adding the distance features, run the following code to report the accuracy.\n",
      "'''\n",
      "reload(depf)\n",
      "\n",
      "dp1 = depp.DependencyParser(feature_function=depf.DependencyFeatures(use_distance=True))\n",
      "dp1.read_data(\"english\")\n",
      "dp1.train_perceptron(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Your answer here)*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Sanity check ** In my case, it makes a very substantial difference, more than 10% absolute improvement."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- ** Lexical features **: Add lexical features between the word of the head and the tag of the modifier, and vice versa.\n",
      "\n",
      "** Deliverable 6 ** How does this impact the total number of features? How does it impact the development accuracy? \n",
      "How does it impact the training set accuracy?\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "After adding the lexical features, run the following code to report the accuracy.\n",
      "'''\n",
      "reload(depf)\n",
      "\n",
      "dp2 = depp.DependencyParser(feature_function=depf.DependencyFeatures(use_distance=True, use_lexical=True))\n",
      "dp2.read_data(\"english\")\n",
      "dp2.train_perceptron(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Your answer here)*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Sanity check ** Again I find a very substantial improvement in development set accuracy."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- ** Bilexical features **: Add bilexical features between the word of the head and the word of the modifier.\n",
      "\n",
      "** Deliverable 7 ** How does this impact the total number of features? How does it impact the development and training accuracy?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "'''\n",
      "After adding the bilexical features, run the following code to report the accuracy.\n",
      "'''\n",
      "reload(depf)\n",
      "\n",
      "dp3 = depp.DependencyParser(feature_function=depf.DependencyFeatures(use_distance=True, use_lexical=True, use_bilexical=True))\n",
      "dp3.read_data(\"english\")\n",
      "dp3.train_perceptron(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Your answer here)*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- ** Context features ** Add context features that consider the tags adjacent to the head and modifier. You may wish to consider \n",
      "various tag combinations, such as \n",
      "\n",
      " - $\\langle t[h], t[h-1], t[m]\\rangle$: head, head-left, modifier\n",
      " - $\\langle t[h], t[m], t[m+1]\\rangle$: head, modifier, modifier-right\n",
      " - $\\langle t[h], t[h-1], t[m], t[m+1]\\rangle$: head, head-left, modifier, modifier-right\n",
      " - etc\n",
      "\n",
      "** Deliverable 8 ** Describe what context feature templates you have added. How do they impact the total number of features? How does \n",
      "it impact the development and training accuracy?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "After adding the contextual features, run the following code to report the accuracy.\n",
      "'''\n",
      "reload(depf)\n",
      "\n",
      "dp4 = depp.DependencyParser(feature_function=depf.DependencyFeatures(use_distance=True, use_lexical=True, \n",
      "                                                                use_bilexical=True, use_contextual=True))\n",
      "dp4.read_data(\"english\")\n",
      "dp4.train_perceptron(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Your answer here)*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.3 Bakeoff! ##\n",
      "\n",
      "You can try to develop any other features that like. Please explain all the features that you have. After identifying your best \n",
      "feature set, run *test()* function from DependencyParser. This will produce a file **data/deppars/english_test.conll.pred**.\n",
      "\n",
      "** Deliverable 9 ** Rename the file to **lastname-firstname.conll.pred** and include it in your t-square submission"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Run the following code to get the prediction on test set\n",
      "\"\"\"\n",
      "reload(depf)\n",
      "\n",
      "## Specify the additional parameters of DependencyFeatures to include your best feature set\n",
      "dp5 = depp.DependencyParser(feature_function=depf.DependencyFeatures(use_distance=True, use_lexical=True, \n",
      "                                                                use_bilexical=True, use_contextual=True))\n",
      "\n",
      "dp5.read_data(\"english\")\n",
      "dp5.train_perceptron(10)\n",
      "dp5.test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 3 Applications of dependency parsing (7650 only)# \n",
      "\n",
      "Find a paper that applies dependency parsing to help solve some other problems, such as *information retrieval, question answering, \n",
      "information extraction, paraphrase, semantic analysis, translation,* etc. Your paper should be selected from the proceedings of ACL, \n",
      "NAACL, EMNLP, WWW, SIGIR, or EACL.\n",
      "\n",
      "** Deliverable 10 ** Report on:\n",
      "\n",
      "- What is the problem that is being solved?\n",
      "- Why is dependency parsing expected to help?\n",
      "- Do they use labeled or unlabeled dependency parses?\n",
      "- What dependency parser do they use?\n",
      "- How is dependency parsing included in the system?\n",
      "- What improvement, if any, does it make?\n",
      "\n",
      "And add any other details of interest."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Your answer here)*"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}